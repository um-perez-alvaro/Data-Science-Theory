{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and plot a toy dataset\n",
    "m = 20 # number of points\n",
    "x = -1 + 2*np.random.rand(m) # m random points over the interval [-1,1]\n",
    "y = 2*x+1+0.25*np.random.randn(m) # y = 2x+1 + random noise\n",
    "plt.figure(figsize=(10,5)) \n",
    "plt.plot(x,y,'o', label='data')\n",
    "plt.xlabel('x',fontsize=20)\n",
    "plt.ylabel('y',fontsize=20)\n",
    "plt.legend(fontsize=15, loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix X\n",
    "X = np.ones((m,2)) \n",
    "X[:,1] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "lr = 0.5 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization:\n",
    "theta = np.random.randn(2) # theta randomly chosen\n",
    "\n",
    "# initial mean squared error\n",
    "MSE = np.linalg.norm(X.dot(theta)-y)/m\n",
    "\n",
    "#plot the data \n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(x,y,'bo')\n",
    "\n",
    "# plot the linear regression model\n",
    "m_plot = 100\n",
    "x_plot = np.linspace(-1,1,100)\n",
    "X_plot = np.ones((m_plot,2))\n",
    "X_plot[:,1] = x_plot\n",
    "y_plot = X_plot.dot(theta)\n",
    "plt.plot(x_plot,y_plot,'r-')\n",
    "\n",
    "plt.title('MSE = '+str(MSE),fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent Step\n",
    "gradient = (2/m)*X.T.dot(X.dot(theta)-y)\n",
    "theta = theta - lr*gradient\n",
    "\n",
    "# Mean squared error\n",
    "MSE = np.linalg.norm(X.dot(theta)-y)/m\n",
    "\n",
    "#plot the data \n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(x,y,'bo')\n",
    "\n",
    "# plot the linear regression model\n",
    "y_plot = X_plot.dot(theta)\n",
    "plt.plot(x_plot,y_plot,'r-')\n",
    "\n",
    "plt.title('MSE = '+str(MSE),fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning 1:** if the learning rate is too small: convergence will take a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization:\n",
    "theta = np.random.randn(2) # theta randomly chosen\n",
    "\n",
    "# initial mean squared error\n",
    "MSE = np.linalg.norm(X.dot(theta)-y)/m\n",
    "\n",
    "#plot the data \n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(x,y,'bo')\n",
    "\n",
    "# plot the linear regression model\n",
    "m_plot = 100\n",
    "x_plot = np.linspace(-1,1,100)\n",
    "X_plot = np.ones((m_plot,2))\n",
    "X_plot[:,1] = x_plot\n",
    "y_plot = X_plot.dot(theta)\n",
    "plt.plot(x_plot,y_plot,'r-')\n",
    "\n",
    "plt.title('MSE = '+str(MSE),fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent Step\n",
    "gradient = (2/m)*X.T.dot(X.dot(theta)-y)\n",
    "theta = theta - lr*gradient\n",
    "\n",
    "# Mean squared error\n",
    "MSE = np.linalg.norm(X.dot(theta)-y)/m\n",
    "\n",
    "#plot the data \n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(x,y,'bo')\n",
    "\n",
    "# plot the linear regression model\n",
    "y_plot = X_plot.dot(theta)\n",
    "plt.plot(x_plot,y_plot,'r-')\n",
    "\n",
    "plt.title('MSE = '+str(MSE),fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning 2:** If the learning rate is too large, the algorithm may diverge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization:\n",
    "theta = np.random.randn(2) # theta randomly chosen\n",
    "\n",
    "# initial mean squared error\n",
    "MSE = np.linalg.norm(X.dot(theta)-y)/m\n",
    "\n",
    "#plot the data \n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(x,y,'bo')\n",
    "\n",
    "# plot the linear regression model\n",
    "m_plot = 100\n",
    "x_plot = np.linspace(-1,1,100)\n",
    "X_plot = np.ones((m_plot,2))\n",
    "X_plot[:,1] = x_plot\n",
    "y_plot = X_plot.dot(theta)\n",
    "plt.plot(x_plot,y_plot,'r-')\n",
    "\n",
    "plt.title('MSE = '+str(MSE),fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent Step\n",
    "gradient = (2/m)*X.T.dot(X.dot(theta)-y)\n",
    "theta = theta - lr*gradient\n",
    "\n",
    "# Mean squared error\n",
    "MSE = np.linalg.norm(X.dot(theta)-y)/m\n",
    "\n",
    "#plot the data \n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(x,y,'bo')\n",
    "\n",
    "# plot the linear regression model\n",
    "y_plot = X_plot.dot(theta)\n",
    "plt.plot(x_plot,y_plot,'r-')\n",
    "\n",
    "plt.title('MSE = '+str(MSE),fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linregression_GD(X,y,learning_rate, n_epochs = 100, return_MSE=False):\n",
    "    '''\n",
    "    linear regression with Gradient Descent\n",
    "    \n",
    "    INPUT: \n",
    "    - the matrix X\n",
    "    - the vector y\n",
    "    - learning rate\n",
    "    - epochs: number of Gradient Descent iterations (defualt 100)\n",
    "    - return_MSE: if True, it returs the mse at each iteration (default False)\n",
    "    \n",
    "    OUTPUT:\n",
    "    - the vector theta\n",
    "    - MSE: error at each iteration\n",
    "    '''\n",
    "    m,n = X.shape # size of data set, number of features\n",
    "    theta = np.random.randn(n) # random initialization\n",
    "    \n",
    "    # initialize MSE vector (only if retur_MSE = True)\n",
    "    if return_MSE:\n",
    "        MSE = np.zeros(n_epochs)\n",
    "    \n",
    "    # gradient descent iterations\n",
    "    for epoch in range(n_epochs):\n",
    "        gradient = (2/m)*X.T.dot(X.dot(theta)-y) # gradient of the mse function\n",
    "        theta = theta - learning_rate*gradient # update the vector theta\n",
    "        # compute mean squared error (only if retur_MSE = True)\n",
    "        if return_MSE:\n",
    "            MSE[epoch] = np.linalg.norm(y-X.dot(theta))**2/m\n",
    "            \n",
    "    return theta, MSE if return_MSE else theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the function works\n",
    "theta, MSE = linregression_GD(X,y,learning_rate=0.1,n_epochs=100, return_MSE=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "# plot data + fitted line\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x,y,'bo')\n",
    "y_plot = X_plot.dot(theta)\n",
    "plt.plot(x_plot,y_plot,'r-')\n",
    "\n",
    "# plot the mean squared error as a function of the number of iterations\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(MSE,'o--')\n",
    "plt.ylabel('error',fontsize=15)\n",
    "plt.xlabel('epoch',fontsize=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
