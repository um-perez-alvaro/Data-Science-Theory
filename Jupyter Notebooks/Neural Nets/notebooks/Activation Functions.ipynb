{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer_dense:\n",
    "      \n",
    "    # initialization (weights and biases)\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.1*np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1,n_neurons))\n",
    "\n",
    "    # output\n",
    "    def forward(self, inputs):\n",
    "        self.output = inputs.dot(self.weights) + self.biases\n",
    "\n",
    "class activation_ReLU:\n",
    "    'rectified linear unit activation function'\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.33768205, -0.37021917],\n",
       "       [-0.79838824,  0.95174488],\n",
       "       [-0.37854034,  0.37279298],\n",
       "       [ 0.15954209, -2.20949721],\n",
       "       [ 0.52225513, -1.25066481],\n",
       "       [ 0.36385951, -0.53693885],\n",
       "       [ 1.27610688, -0.29306088],\n",
       "       [ 1.440094  ,  0.09836132],\n",
       "       [ 0.80992828, -0.27905734],\n",
       "       [-0.21290053, -0.41871452]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randn(10,2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create multiple layers\n",
    "layer1 = layer_dense(n_inputs = 2, n_neurons = 5)\n",
    "activation1 = activation_ReLU()\n",
    "layer2 = layer_dense(n_inputs = 5, n_neurons = 10)\n",
    "activation2 = activation_ReLU()\n",
    "layer3 = layer_dense(n_inputs =10, n_neurons = 2)\n",
    "activation3 = activation_ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 1\n",
    "layer1.forward(X)\n",
    "activation1.forward(layer1.output)\n",
    "# layer 2\n",
    "layer2.forward(activation1.output)\n",
    "activation2.forward(layer2.output)\n",
    "# layer 3\n",
    "layer3.forward(activation2.output)\n",
    "activation3.forward(layer3.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.51006180e-03, 1.05479889e-02],\n",
       "       [0.00000000e+00, 5.69555442e-04],\n",
       "       [0.00000000e+00, 2.29976440e-05],\n",
       "       [0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.68693656e-03],\n",
       "       [1.78576392e-04, 1.52349252e-03],\n",
       "       [2.35150727e-03, 1.02004590e-02],\n",
       "       [1.96952078e-03, 1.21943206e-02],\n",
       "       [1.46527372e-03, 6.15367971e-03],\n",
       "       [0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output\n",
    "activation3.output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
