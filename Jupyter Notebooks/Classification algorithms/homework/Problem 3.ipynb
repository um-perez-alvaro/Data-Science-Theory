{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Visualizing Classification Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moons dataset is a simple built-in dataset from the [scikit-learn library](https://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to generate and visualize the dataset\n",
    "from sklearn.datasets import make_moons\n",
    "X,y = make_moons(n_samples=1000,noise=0.2)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(X[y==0,0],X[y==0,1],'o',label = 'class '+str(0))\n",
    "plt.plot(X[y==1,0],X[y==1,1],'o',label = 'class '+str(1))\n",
    "plt.legend(fontsize=15)\n",
    "plt.title('Moons dataset', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a **logistic regression** model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your logistic regression model will split the feature space into regions called **classification regions**. \n",
    "All points in a classification region are assigned to the same class.\n",
    "Run the following two cells to visualize the decision regions.\n",
    "Notice that the boundary between regions is linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_regions(X, y, theta, degree=0, bias=False):\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    from itertools import chain\n",
    "    from itertools import combinations_with_replacement as comb_w_r\n",
    "    \n",
    "    # create a 100x100 meshgrid\n",
    "    m_plot = 100\n",
    "    x1 = np.linspace(X[:,0].min()-0.5, X[:,0].max()+0.5, m_plot)\n",
    "    x2 = np.linspace(X[:,1].min()-0.5,X[:,1].max()+0.5, m_plot)\n",
    "    X1, X2 = np.meshgrid(x1, x2) \n",
    "    X_plot = np.c_[X1.ravel(), X2.ravel()]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # polynomial features\n",
    "    if degree==0:\n",
    "        X_plot_poly = X_plot\n",
    "    else:\n",
    "        n = 2\n",
    "        # number of polynomial features\n",
    "        combinations  = chain.from_iterable(comb_w_r(range(n), i) for i in range(1, degree+1))\n",
    "        n_poly = sum(1 for comb in combinations)\n",
    "        # add polynomial features\n",
    "        combinations  = chain.from_iterable(comb_w_r(range(n), i) for i in range(1, degree+1))\n",
    "        X_plot_poly = np.ones((m_plot**2,n_poly))\n",
    "        for col_idx,combination in enumerate(combinations):  \n",
    "            for idx in combination:\n",
    "                X_plot_poly[:,col_idx]= X_plot_poly[:,col_idx]*X_plot[:,idx]\n",
    "    # add bias            \n",
    "    if bias:\n",
    "        X_plot_poly = np.c_[np.ones(m_plot**2),X_plot_poly]\n",
    "\n",
    "    # evaluate the log regression model  at each point of the mesh grid    \n",
    "    y_plot = sigmoid(X_plot_poly.dot(theta))\n",
    "        \n",
    "    # class prediction    \n",
    "    y_plot[y_plot>=0.5]=1\n",
    "    y_plot[y_plot<0.5]=0\n",
    "    y_plot = y_plot.reshape(X1.shape)\n",
    "\n",
    "    custom_cmap = ListedColormap(['#9898ff','#fafab0'])\n",
    "    # contour map\n",
    "    colors = ['blue','red','green']\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.contourf(X1, X2, y_plot, alpha=0.3, cmap=custom_cmap)\n",
    "    \n",
    "    \n",
    "    plt.plot(X[y==0,0],X[y==0,1],'o',label = 'class '+str(0))\n",
    "    plt.plot(X[y==1,0],X[y==1,1],'o',label = 'class '+str(1))\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.title('Moons dataset', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to visualize the classification regions\n",
    "plot_classification_regions(X, y, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the polynomial features of degree 3 and the bias term to your logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to visualize the new decision regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_regions(X, y, theta, degree=degree, bias=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
