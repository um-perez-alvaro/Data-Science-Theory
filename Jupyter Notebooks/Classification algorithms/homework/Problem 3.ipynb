{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color, feature\n",
    "from skimage import data, transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: A Simple Face Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build a simple facial detection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using pixel intensities as features (as you did in Problem 2), we'll use the **HOG (Histrogram of Oriented Gradients) features**.\n",
    "[HOG features](https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients) focus on the structure or the shape of an object, and they are widely used in computer vision tasks for object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'visualization of HOG features'\n",
    "\n",
    "image = color.rgb2gray(data.chelsea()) #load an image\n",
    "hog_vec, hog_vis = feature.hog(image,visualize=True) #extract HOG features\n",
    "\n",
    "'plot image and hog features'\n",
    "fig, ax = plt.subplots(1,2, figsize = (12,6),\n",
    "                       subplot_kw=dict(xticks=[],yticks=[]))\n",
    "ax[0].imshow(image,cmap='gray')\n",
    "ax[0].set_title('original image',fontsize=15)\n",
    "\n",
    "ax[1].imshow(hog_vis,cmap = 'gray')\n",
    "ax[1].set_title('visualization of HOG features',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our face detector, we need\n",
    "\n",
    "1. **A set of face images**\n",
    "2. **A set of nonface images**\n",
    "3. **To extract the HOG features from all the images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A set of face images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the Labeled Faces in the Wild dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell to load the labeled faces in the wild dataset\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people() \n",
    "positive_patches = faces.images/255\n",
    "\n",
    "positive_patches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive_patches dataset contains 8211 images, and each image has 2914 (62x47) features. Each feature simply represents one pixel's intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(100):\n",
    "    face_image = positive_patches[i]\n",
    "    plt.subplot(10,10,i+1)\n",
    "    plt.imshow(face_image,cmap = 'gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a sample of 8211 face images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A set of nonface images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'camera'\n",
    "getattr(data,name)().ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs_to_use = ['camera','text','coins','moon','page','clock','immunohistochemistry','chelsea','coffee','hubble_deep_field']\n",
    "images = [color.rgb2gray(getattr(data,name)())/255 \n",
    "          if getattr(data,name)().ndim == 3 \n",
    "          else getattr(data,name)()/255 \n",
    "          for name in imgs_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    plt.subplot(5,2,i+1)\n",
    "    plt.imshow(images[i],cmap='gray')\n",
    "    plt.title(imgs_to_use[i],fontsize=15)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll extract 62x47 thumbnails from these 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.image import PatchExtractor\n",
    "def extract_patches(img,N,scale=1.0,patch_size=positive_patches[0].shape):\n",
    "    extracted_patch_size = tuple((scale*np.array(patch_size)).astype(int))\n",
    "    extractor = PatchExtractor(patch_size=extracted_patch_size,max_patches=N,random_state=0)\n",
    "    patches = extractor.transform(img[np.newaxis])\n",
    "    if scale !=1:\n",
    "        patches = np.array([transform.resize(patch,patch_size) for patch in patches])\n",
    "    return patches\n",
    "\n",
    "negative_patches = np.vstack([extract_patches(im,500,scale) for im in images for scale in [1.0, 2.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'display 100 (randomly chosen) nonface images'\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(100):\n",
    "    plt.subplot(10,10,i+1)\n",
    "    plt.imshow(negative_patches[np.random.randint(10000)],cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_patches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a sample of 10,000 nonface images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine sets and extract HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_positive_patches = np.array([feature.hog(img) for img in positive_patches])\n",
    "hog_negative_patches = np.array([feature.hog(img) for img in negative_patches])\n",
    "\n",
    "'feature matrix'\n",
    "X = np.r_[hog_positive_patches, hog_negative_patches]\n",
    "\n",
    "'label vector'\n",
    "y = np.zeros(X.shape[0]) # 1 = face; 0 = nonface\n",
    "y[:positive_patches.shape[0]]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a logistic regression model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the logistic regression model, write a function that classifies a set of images as a face/nonface images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_classifier(X,theta):\n",
    "    p =\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now that we have a logistic regression model in place, let's grab a new image and see how the model does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg \n",
    "from skimage import io\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/um-perez-alvaro/Data-Science-Practice-bis/master/Classification/Homework/Images/friends.jpg'\n",
    "new_image = io.imread(url)/255\n",
    "\n",
    "#new_image = color.rgb2gray(new_image)/255 #transform image into gray scale\n",
    "plt.imshow(new_image,cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pass a sliding window across the image, using the classifier function to evaluate whether that window contains a face or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(img,patch_size=positive_patches[0].shape,\n",
    "                  istep=2,jstep=2,scale=1.0):\n",
    "    Ni,Nj = (int(scale*s) for s in patch_size)\n",
    "    for i in range(0,img.shape[0]-Ni,istep):\n",
    "        for j in range(0,img.shape[1]-Ni,jstep):\n",
    "            patch = img[i:i+Ni,j:j+Nj]\n",
    "            if scale !=1:\n",
    "                patch - transform.resize(patch,patch_size)\n",
    "            yield(i,j), patch\n",
    "            \n",
    "indices, patches = zip(*sliding_window(new_image)) #apply sliding_window to new_image\n",
    "patches_hog = np.array([feature.hog(patch) for patch in patches]) #extract HOG features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can take the HOG features patches and use the classifier function to evaluate whether each patch contains a face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = face_classifier(patches_hog,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'draw a red rectangle where the classifier function has found a face'\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(new_image,cmap='gray')\n",
    "ax.axis('off')\n",
    "\n",
    "Ni,Nj = positive_patches[0].shape\n",
    "indices = np.array(indices)\n",
    "for i,j in indices[labels == 1]:\n",
    "    ax.add_patch(plt.Rectangle((j,i), Nj,Ni,edgecolor='red',alpha=0.3,lw=2,facecolor='none'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the face detector on the following image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to load the image\n",
    "import matplotlib.image as mpimg \n",
    "from skimage import transform\n",
    "from skimage import io\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/um-perez-alvaro/log-regress/master/yourfavouriteprofessor.jpg'\n",
    "new_image = io.imread(url)\n",
    "\n",
    "new_image = color.rgb2gray(new_image) #transform image into gray scale\n",
    "s = 3.25 # scale new_image\n",
    "new_image = transform.resize(new_image, (new_image.shape[0]//s, new_image.shape[1]//s))\n",
    "\n",
    "plt.imshow(new_image,cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
