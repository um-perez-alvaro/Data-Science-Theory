{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax regression is a generalization of logistic regression to the case where we want to handle multiple classes (k  classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contents**\n",
    "\n",
    "- [Softmax Regression](#1.-Softmax-Regression)\n",
    "- [Example: The Iris Dataset](#2.-Example:-The-Iris-Dataset)\n",
    "- [Example: The Palmer Archipelago Penguin Dataset](#3.-Example:-The-Palmer-Archipelago-Penguin-Dataset)\n",
    "- [Example: Oranges, Lemons and Apples dataset](#4.-Example:-Oranges,-Lemons-and-Apples-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(v):\n",
    "    # labels\n",
    "    labels = np.unique(v)\n",
    "    # ordinal encoding\n",
    "    dic_labels = {labels[i]:i for i in range(len(labels))}\n",
    "    ord_labels = np.array([dic_labels[v[i]] for i in range(len(v))])\n",
    "    # one-hot encoding\n",
    "    V = np.zeros((len(v),len(labels)))\n",
    "    V[np.arange(len(v)),ord_labels] = 1\n",
    "    # return one-hot-encodings and the class labels\n",
    "    return V,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chekc that it works\n",
    "y = np.array(['Spain','Italy','Italy','USA','Italy'])\n",
    "Y, labels = one_hot_encoding(y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X,theta):\n",
    "    m,n = X.shape\n",
    "    Y = np.exp(X.dot(theta))\n",
    "    row_sum = np.sum(Y,axis=1).reshape(-1,1)\n",
    "    return Y/row_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that it works; notice that the entries of each row add to 1'\n",
    "X = np.random.randn(5,2) # 5 data points, 2 features\n",
    "theta = np.random.randn(2,3) # 2 features, 3 classes\n",
    "softmax(X,theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The softmax cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cost(X,Y,theta):\n",
    "    m = X.shape[0]\n",
    "    P = softmax(X,theta)\n",
    "    return -np.sum(Y*np.log(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_cost(X,Y,theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxregression_GD(X,y,learning_rate,n_epochs):\n",
    "    \n",
    "    # one-hot-encoding function\n",
    "    def one_hot_encoding(v):\n",
    "        # labels\n",
    "        labels = np.unique(v)\n",
    "        # ordinal encoding\n",
    "        dic_labels = {labels[i]:i for i in range(len(labels))}\n",
    "        ord_labels = np.array([dic_labels[v[i]] for i in range(len(v))])\n",
    "        # one-hot encoding\n",
    "        V = np.zeros((len(v),len(labels)))\n",
    "        V[np.arange(len(v)),ord_labels] = 1\n",
    "        return V,labels\n",
    "    \n",
    "    # softmax function\n",
    "    def softmax(X,theta):\n",
    "        m,n = X.shape\n",
    "        Y = np.exp(X.dot(theta))\n",
    "        row_sum = np.sum(Y,axis=1).reshape(-1,1)\n",
    "        return Y/row_sum\n",
    "    \n",
    "    # softmax cost function\n",
    "    def softmax_cost(X,Y,theta):\n",
    "        m = X.shape[0]\n",
    "        P = softmax(X,theta)\n",
    "        return -np.sum(Y*np.log(P))\n",
    "    \n",
    "    m,n = X.shape\n",
    "    k = len(np.unique(y))\n",
    "        \n",
    "    # initialize vector theta\n",
    "    theta = np.random.randn(n,k)\n",
    "    \n",
    "    # initialize cost vector\n",
    "    cost = np.zeros(n_epochs)\n",
    "    \n",
    "    # one-hot encodings\n",
    "    Y,labels = one_hot_encoding(y)\n",
    "    \n",
    "    # gradient descent iterations  \n",
    "    for i in range(n_epochs):\n",
    "        gradient = X.T.dot(softmax(X,theta)-Y)\n",
    "        theta = theta - learning_rate * gradient\n",
    "        cost[i] = softmax_cost(X,Y,theta)\n",
    "            \n",
    "\n",
    "    return theta,cost,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example: The Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"iris.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris flower data set is a data set introduced by the British statistician, and biologist Ronald Fisher in his 1936 paper *The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "url = 'https://raw.githubusercontent.com/um-perez-alvaro/Data-Science-Practice/master/Data/iris.csv'\n",
    "data = pd.read_csv(url)\n",
    "data.head(5) #first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of 3 different types of irises’ (Setosa, Versicolour, and Virginica) petal and sepal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature matrix\n",
    "X = data[['sepal_length','sepal_width','petal_length','petal_width']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target vector\n",
    "y = data['species'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "Y = one_hot_encoding(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,cost,labels = softmaxregression_GD(X,y,\n",
    "                                         learning_rate = 0.0001,\n",
    "                                         n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_softmax(X,theta,labels):\n",
    "    P = softmax(X,theta)\n",
    "    return labels[np.argmax(P,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor_softmax(X,theta,labels)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Confusion matrix'\n",
    "def confusion_matrix(y,y_pred,labels):\n",
    "    C = np.zeros((len(labels),len(labels)))\n",
    "    for i,label_i in enumerate(labels):\n",
    "        for j,label_j in enumerate(labels):\n",
    "            C[i,j]=sum(y_pred[y==label_i]==label_j)\n",
    "    return C\n",
    "confusion_matrix(y,y_pred,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'percentage of correct classification'\n",
    "100*np.sum(y_pred==y)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example: The Palmer Archipelago Penguin Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cute_penguins.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Art by @allison_horst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "url = 'https://raw.githubusercontent.com/um-perez-alvaro/Data-Science-Theory/master/Data/penguins_size.csv'\n",
    "data = pd.read_csv(url)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains data for 344 penguins. There are 3 different species of penguins in this dataset, collected from 3 islands in the Palmer Archipelago, Antarctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.species.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The culmen is the upper ridge of a bird’s bill. For this penguin data, the culmen (bill) length and depth are measured as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"culmen_depth.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rows contain missing values. We will drop them from the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target vector\n",
    "y = data['species'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature matrix\n",
    "X = data[['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "X = X/X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,cost,labels = softmaxregression_GD(X,y,\n",
    "                                        learning_rate = 0.001,\n",
    "                                        n_epochs=5000,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor_softmax(X,theta,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Confusion matrix'\n",
    "confusion_matrix(y,y_pred,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'percentage of incorrect classification'\n",
    "100*np.sum(y_pred==y)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example: Oranges, Lemons and Apples dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fruits.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset *fruits.csv* contains measurements of the height (cm), width (cm) and mass (g) of a selection of oranges, lemons and apples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "url = 'https://raw.githubusercontent.com/um-perez-alvaro/Data-Science-Theory/master/Data/fruits.csv'\n",
    "data = pd.read_csv(url)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data[['height', 'width', 'mass']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "X = X/X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =  data['fruit'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,cost,labels = softmaxregression_GD(X,y,\n",
    "                               learning_rate = 0.01,\n",
    "                               n_epochs=5000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor_softmax(X,theta,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Confusion matrix'\n",
    "confusion_matrix(y,y_pred,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'percentage of incorrect classification'\n",
    "100*np.sum(y_pred==y)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Three spirals dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 4\n",
    "n_points = 500\n",
    "noise = 0.35\n",
    "radius = 10\n",
    "\n",
    "X = np.zeros((n_points*classes, 2))\n",
    "y = np.zeros(n_points*classes).astype('int')\n",
    "\n",
    "for class_number in range(classes):\n",
    "    ix = range(n_points*class_number, n_points*(class_number+1))\n",
    "    r = np.linspace(0,1, n_points)\n",
    "    t = np.linspace(class_number*radius, (class_number+1)*radius, n_points) + np.random.randn(n_points)*noise\n",
    "    X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "    y[ix] = class_number\n",
    "    \n",
    "plt.plot(X[y==0,0],X[y==0,1],'o',label = 'class 0')\n",
    "plt.plot(X[y==1,0],X[y==1,1],'o',label = 'class 1')\n",
    "plt.plot(X[y==2,0],X[y==2,1],'o',label = 'class 2')\n",
    "plt.plot(X[y==3,0],X[y==3,1],'o',label = 'class 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly_features(X,degree):\n",
    "    from itertools import combinations_with_replacement as comb_w_r\n",
    "    from itertools import chain\n",
    "    \n",
    "    # number of datapoints (rows), number of features (columns)\n",
    "    try:\n",
    "        m,n = X.shape # this won't work if X is a vector (n=1 features)\n",
    "    except: \n",
    "        m = len(X)\n",
    "        n = 1\n",
    "        X = X.reshape(m,1) #  \n",
    "    \n",
    "    # number of polynomial features\n",
    "    combinations = chain.from_iterable(comb_w_r(range(n),i) for i in range(degree+1))\n",
    "    n_poly = sum(1 for combination in combinations) \n",
    "    \n",
    "    # polynomial features matrix\n",
    "    X_poly = np.ones((m,n_poly))\n",
    "    combinations = chain.from_iterable(comb_w_r(range(n),i) for i in range(degree+1))\\\n",
    "    \n",
    "    \n",
    "    for column_index, combination in enumerate(combinations):\n",
    "        X_poly[:,column_index] = np.prod(X[:,combination],axis=1)\n",
    "        \n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = build_poly_features(X,degree=10)\n",
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,cost,labels = softmaxregression_GD(X_poly,y,\n",
    "                                        learning_rate = 0.001,\n",
    "                                        n_epochs=20000,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_softmax_regions(X, y, theta, labels, degree=1):\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    \n",
    "    # softmax predictor function\n",
    "    def predictor_softmax(X,theta,labels):\n",
    "        P = softmax(X,theta)\n",
    "        return labels[np.argmax(P,axis=1)]\n",
    "    \n",
    "    # create a 500x500 meshgrid\n",
    "    m_plot = 500\n",
    "    x1 = np.linspace(X[:,0].min()-0.5, X[:,0].max()+0.5, m_plot)\n",
    "    x2 = np.linspace(X[:,1].min()-0.5,X[:,1].max()+0.5, m_plot)\n",
    "    X1, X2 = np.meshgrid(x1, x2) \n",
    "    X_plot = np.c_[X1.ravel(), X2.ravel()]\n",
    "    \n",
    "    # add polynomial features\n",
    "    X_plot_poly = build_poly_features(X_plot,degree=degree)\n",
    "\n",
    "    # evaluate the softmax regression model at each point of the mesh grid    \n",
    "    y_plot = predictor_softmax(X_plot_poly,theta,labels).reshape(X1.shape)        \n",
    "\n",
    "\n",
    "    # custom color map\n",
    "    k = len(labels)\n",
    "    custom_cmap = ListedColormap(['C'+str(i) for i in range(k)])\n",
    "    \n",
    "    # softmax classification regions\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.contourf(X1, X2, y_plot, alpha=0.3, cmap=custom_cmap)\n",
    "    \n",
    "    # plot data points\n",
    "    for label in labels:\n",
    "        plt.scatter(X[y==label,0],X[y==label,1], label=label)\n",
    "        \n",
    "    plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_softmax_regions(X, y, theta, labels, degree=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
