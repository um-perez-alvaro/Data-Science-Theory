{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date: 03/29/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.3 Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral Clustering is an alternative clustering algorithm to k-means and Hierarchical Clustering.\n",
    "Spectral Clustering can capture complex cluster structures and, unlike Hierarchical Clustering, can handle medium/large sized datasets.\n",
    "Its drawback: Spectral Clustering has human-specified parameter $\\sigma$. \n",
    "It is, however, possible to deduce a good parameter $\\sigma$ by trial and error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral clustering has a long history. \n",
    "As a machine learning method, it was popularized by Ng, Jordan, and Weiss:\n",
    "\n",
    "https://ai.stanford.edu/~ang/papers/nips01-spectral.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral Clustering uses the eigenvectors of the **Laplacian matrix**. The Laplacian matrix is constructed as follows.\n",
    "First, we form the **affinity matrix**. The affinity matrix $A$ is an $m\\times m$ (where $m$ is the size of the dataset) whose $(i,j)$ entry is\n",
    "\n",
    "$$\n",
    "A_{ij} = \\exp \\left(\\frac{-\\|x_i-x_j\\|_2^2}{2\\sigma^2}\\right).\n",
    "$$\n",
    "\n",
    "The parameter $\\sigma$ controls how rapidly the affinity $A_{ij}$ falls off with the distance between the points $x_i$ and $x_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we form the **degree matrix**. The degree matrix $D$ is an $m\\times m$ diagonal matrix whose $(i,i)$ entry is the sum of A's $i$th row.\n",
    "\n",
    "$$\n",
    "D_{ii} = \\sum_{j=1}^m A_{ij}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Laplaciam matrix** is the symmetric matrix\n",
    "\n",
    "$$\n",
    "L = D^{-1/2} A D^{-1/2},\n",
    "$$\n",
    "\n",
    "where $D^{-1/2}$ denotes the matrix inverse of $D^{1/2}$, and where $D^{1/2}$ is a diagonal matrix whose $(i,i)$ entry is the square root of the $(i,i)$ entry of $D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Laplacian_matrix(X,sigma):\n",
    "    \n",
    "    'dataset size and number of features'\n",
    "    m,n=X.shape\n",
    "    \n",
    "    'affinity matrix'\n",
    "    A = np.zeros((m,m))\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            A[i,j] = np.linalg.norm(X[i]-X[j])\n",
    "    A = np.exp(-A/(2*sigma**2))\n",
    "    \n",
    "    'degree matrix'\n",
    "    D = np.sum(A,axis=1)\n",
    "    \n",
    "    'return Laplacian matrix'\n",
    "    return ((A/np.sqrt(D)).T/np.sqrt(D)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spectral Clustering** works as follows: given a set of points $x_1,\\ldots,x_m$ that we want to cluster into $k$ subsets:\n",
    "\n",
    "**step 1**. Form the Laplacian matrix\n",
    "\n",
    "**step 2**. Find the eigenvectors $v_1,v_2,\\ldots,v_k$ of the Laplacian matrix corresponding to the $k$ largest eigenvalues. Form the matrix\n",
    "\n",
    "$$\n",
    "V = \n",
    "\\begin{bmatrix}\n",
    "    v_1 & v_2 & \\cdots & v_k\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "by staking the eigenvectors in columns.\n",
    "\n",
    "**step 3**. Normalize each of $V$'s rows to have unit norm.\n",
    "\n",
    "**step 4**. Treating each row of $V$ as a point, cluster them into $k$ clusters via the $k$-means algorithm (or any other cluster algorithm)\n",
    "\n",
    "**step 5**. Assign the orinal point $x_i$ to cluster $j$ if and only if row $i$ of $V$ was assigned to cluster $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3.1 Spectral Clustering Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the following dataset with two clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((400,2))\n",
    "\n",
    "# cluster 1:\n",
    "theta = np.linspace(0,2*np.pi,200) \n",
    "X[0:200,0] = 8*np.sin(theta)+0.1*np.random.randn(200)\n",
    "X[0:200,1] = 8*np.cos(theta)+0.1*np.random.randn(200)\n",
    "# cluster 2:\n",
    "X[200:400] = 0.4*np.random.randn(200,2)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(X[:,0],X[:,1],'bo',alpha=0.5,markersize=10)\n",
    "plt.title('ring-shaped dataset',fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by forming the Laplacian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "L = Laplacian_matrix(X,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we compute the eigenvectors with the $k=2$ largest eigenvalues.\n",
    "To do this, we'll use the function eigs in the scipy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "_,V = scipy.sparse.linalg.eigs(L, k=2,which='LM') #'LM' = largest magnitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we normalize the rows of V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'normalize rows'\n",
    "V = V/np.linalg.norm(V,axis=1,keepdims=True)\n",
    "V = np.real(V) # remove the imaginary parts (which are all equal to 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the magic. Steps 1--3 maps the original points to points in the unit circle. The two original clusters (the outer circle and the blob at the origin) are transformed into two tight clusters that lie at 90 degrees to each other relative to the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "'original dataset'\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(X[:,0],X[:,1],'bo',alpha=0.5,markersize=10)\n",
    "plt.title('original dataset',fontsize=30)\n",
    "\n",
    "'transformed dataset + unit circle'\n",
    "theta = np.linspace(0,2*np.pi,1000) \n",
    "x_unit_circle = np.sin(theta)\n",
    "y_unit_circle = np.cos(theta)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(V[:,0],V[:,1],'bo',alpha=0.6)\n",
    "plt.plot(x_unit_circle,y_unit_circle,'r--',label='unit circle')\n",
    "plt.legend(fontsize=15,loc='upper left')\n",
    "plt.title('transformed dataset',fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformed clusters can be easily found by the k-means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(X,k,max_it=1000000):   \n",
    "    it = 0 \n",
    "    m,n = X.shape #dataset size, number of features\n",
    "    repeat = True \n",
    "    'random initialization of clusters'\n",
    "    clusters = np.random.randint(k,size=len(X)) # random assignment\n",
    "    'means initialization'\n",
    "    means = np.zeros((k,n))\n",
    "    while repeat and it<=max_it: # repeat until clusters do not change or iterations > max_it\n",
    "        it = it + 1\n",
    "        'step 1: update means'\n",
    "        for i in range(k):\n",
    "            if len(X[clusters==i])!=0:\n",
    "                means[i] = np.mean(X[clusters==i],axis=0)\n",
    "            else: # if any of the cluster centers has no data points associated with it, replace it with a random data point\n",
    "                idx = np.random.randint(m)\n",
    "                means[i] = X[idx]\n",
    "        'step 2: update clusters'\n",
    "        new_clusters = np.argmin(np.array([np.linalg.norm(X-means[i],axis=1) for i in range(k)]),axis=0)        \n",
    "        'check whether clusters and new_clusters are equal or not'\n",
    "        if sum(clusters!=new_clusters)==0:\n",
    "            repeat = False\n",
    "        clusters = new_clusters\n",
    "    return clusters, means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'apply k-means'\n",
    "clusters,_ = k_means(V,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['green','blue']\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(x_unit_circle,y_unit_circle,'r--',label='unit circle')\n",
    "k=2\n",
    "for i in range(k):\n",
    "    plt.plot(V[clusters==i,0],V[clusters==i,1],'o',color=colors[i],label = 'transformed cluster '+str(i),alpha=0.5,markersize=15)\n",
    "    plt.legend(fontsize=20, loc='lower left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = ['blue','green']\n",
    "plt.figure(figsize=(12,5))\n",
    "k=2\n",
    "for i in range(k):\n",
    "    'plot dataset points'\n",
    "    plt.plot(X[clusters==i,0],X[clusters==i,1],'o',color=colors[i],label = 'cluster '+str(i),alpha=0.6,markersize=15)\n",
    "    plt.legend(fontsize=20, loc='lower left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3.2 Spectral Clustering Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(X,k,sigma):\n",
    "    \n",
    "    'form Laplacian matrix'\n",
    "    L = Laplacian_matrix(X,sigma=sigma)\n",
    "    \n",
    "    'find k largest eigenvectors'\n",
    "    _,V = scipy.sparse.linalg.eigs(L, k=2,which='LM')\n",
    "    \n",
    "    'normalize rows of V'\n",
    "    V = V/np.linalg.norm(V,axis=1,keepdims=True)\n",
    "    V = np.real(V) # remove the imaginary parts (which are all equal to 0)\n",
    "    \n",
    "    'apply k-means to rows of V'\n",
    "    clusters,_ = k_means(V,k)\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3.3 Questions/Problems (some of these problems might appear in Homework 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1:** try to replicate the examples in Section 4 (see Figure 1) in the paper https://ai.stanford.edu/~ang/papers/nips01-spectral.pdf\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
